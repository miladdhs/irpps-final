#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø­ØªÙˆØ§ÛŒ Ú©Ø§Ù…Ù„ Ø§Ø² Ù‡Ù…Ù‡ ØªØµØ§ÙˆÛŒØ± Ùˆ ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ø³Ø§Ø®ØªØ§Ø± JSON
"""

import json
import re
from datetime import datetime
from pathlib import Path
import base64

CONTENT_DIR = Path("frontend/public/Content")
OUTPUT_FILE = "images_content_extracted.json"

def persian_to_slug(text):
    """ØªØ¨Ø¯ÛŒÙ„ Ù…ØªÙ† ÙØ§Ø±Ø³ÛŒ Ø¨Ù‡ Ø§Ø³Ù„Ø§Ú¯"""
    if not text:
        return ""
    
    persian_digits = 'Û°Û±Û²Û³Û´ÛµÛ¶Û·Û¸Û¹'
    english_digits = '0123456789'
    for i, p in enumerate(persian_digits):
        text = text.replace(p, english_digits[i])
    
    persian_to_latin = {
        'Ø¢': 'a', 'Ø§': 'a', 'Ø¨': 'b', 'Ù¾': 'p', 'Øª': 't', 'Ø«': 's',
        'Ø¬': 'j', 'Ú†': 'ch', 'Ø­': 'h', 'Ø®': 'kh', 'Ø¯': 'd', 'Ø°': 'z',
        'Ø±': 'r', 'Ø²': 'z', 'Ú˜': 'zh', 'Ø³': 's', 'Ø´': 'sh', 'Øµ': 's',
        'Ø¶': 'z', 'Ø·': 't', 'Ø¸': 'z', 'Ø¹': 'a', 'Øº': 'gh', 'Ù': 'f',
        'Ù‚': 'gh', 'Ú©': 'k', 'Ú¯': 'g', 'Ù„': 'l', 'Ù…': 'm', 'Ù†': 'n',
        'Ùˆ': 'v', 'Ù‡': 'h', 'ÛŒ': 'y', 'Ø¦': 'y', 'ÙŠ': 'y',
        ' ': '-', '_': '-', '.': '', ',': '', 'ØŒ': ''
    }
    
    result = []
    for char in text:
        if char in persian_to_latin:
            result.append(persian_to_latin[char])
        elif char.isalnum():
            result.append(char.lower())
        elif char in ['-', '_']:
            result.append('-')
    
    slug = ''.join(result)
    slug = re.sub(r'[^a-z0-9-]', '', slug.lower())
    slug = re.sub(r'-+', '-', slug)
    slug = slug.strip('-')
    
    if not slug:
        slug = 'image-' + str(abs(hash(text)) % 10000)
    
    return slug

def extract_short_content(content, max_length=500):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø®Ù„Ø§ØµÙ‡"""
    if not content:
        return None
    
    content = re.sub(r'\s+', ' ', content).strip()
    if len(content) <= max_length:
        return content
    
    truncated = content[:max_length]
    last_period = truncated.rfind('.')
    if last_period > max_length * 0.7:
        return truncated[:last_period + 1]
    return truncated + '...'

def analyze_image_content(image_path):
    """ØªØ­Ù„ÛŒÙ„ Ù…Ø­ØªÙˆØ§ÛŒ ØªØµÙˆÛŒØ± - Ø¯Ø± Ø§ÛŒÙ†Ø¬Ø§ Ø§Ø² ØªÙˆØ¶ÛŒØ­Ø§Øª Ù…ÙˆØ¬ÙˆØ¯ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…"""
    filename = image_path.name
    file_stem = Path(filename).stem
    
    # ØªØ¹ÛŒÛŒÙ† Ù†ÙˆØ¹ Ùˆ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§Ø² Ù†Ø§Ù… ÙØ§ÛŒÙ„
    content_type = "news"
    category = "Ø¹Ù…ÙˆÙ…ÛŒ"
    tags = "ØªØµÙˆÛŒØ±,Ú¯Ø§Ù„Ø±ÛŒ"
    
    # ØªØ­Ù„ÛŒÙ„ Ù†Ø§Ù… ÙØ§ÛŒÙ„ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø·Ù„Ø§Ø¹Ø§Øª
    title = None
    content = ""
    event_info = {}
    
    if "photo_2025" in filename or "photo-2025" in filename:
        # ØªØµØ§ÙˆÛŒØ± Ù‡Ù…Ø§ÛŒØ´
        category = "Ù‡Ù…Ø§ÛŒØ´"
        tags = "Ù‡Ù…Ø§ÛŒØ´,ØªØµÙˆÛŒØ±,Ú¯Ø§Ù„Ø±ÛŒ,Ø±ÙˆÛŒØ¯Ø§Ø¯"
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØªØ§Ø±ÛŒØ®
        date_match = re.search(r'(\d{4})-(\d{2})-(\d{2})_(\d{2})-(\d{2})-(\d{2})', filename)
        if date_match:
            year, month, day, hour, minute, second = date_match.groups()
            title = f"ØªØµÙˆÛŒØ± Ù‡Ù…Ø§ÛŒØ´ Ø³Ø§Ù„ÛŒØ§Ù†Ù‡ Ø±ÛŒÙ‡ Ú©ÙˆØ¯Ú©Ø§Ù† - {year}/{month}/{day} Ø³Ø§Ø¹Øª {hour}:{minute}:{second}"
            event_info["date"] = f"{year}/{month}/{day}"
            event_info["time"] = f"{hour}:{minute}:{second}"
        else:
            file_id = file_stem.split('_')[-1] if '_' in file_stem else file_stem[-5:]
            title = f"ØªØµÙˆÛŒØ± Ù‡Ù…Ø§ÛŒØ´ Ø³Ø§Ù„ÛŒØ§Ù†Ù‡ Ø±ÛŒÙ‡ Ú©ÙˆØ¯Ú©Ø§Ù† - {file_id}"
        
        content = f"""Ø§ÛŒÙ† ØªØµÙˆÛŒØ± Ø§Ø² Ù…Ø¬Ù…ÙˆØ¹Ù‡ ØªØµØ§ÙˆÛŒØ± Ù‡Ù…Ø§ÛŒØ´ Ø³Ø§Ù„ÛŒØ§Ù†Ù‡ Ø§Ù†Ø¬Ù…Ù† Ø¹Ù„Ù…ÛŒ Ø±ÛŒÙ‡ Ú©ÙˆØ¯Ú©Ø§Ù† Ø§ÛŒØ±Ø§Ù† Ø§Ø³Øª. 

ØªØµÙˆÛŒØ± Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ø±ÙˆÛŒØ¯Ø§Ø¯Ù‡Ø§ÛŒ Ø¹Ù„Ù…ÛŒ Ùˆ ØªØ®ØµØµÛŒ Ø¨Ø±Ú¯Ø²Ø§Ø± Ø´Ø¯Ù‡ Ø¯Ø± Ø²Ù…ÛŒÙ†Ù‡ Ø¨ÛŒÙ…Ø§Ø±ÛŒâ€ŒÙ‡Ø§ÛŒ Ø±ÛŒÙˆÛŒ Ú©ÙˆØ¯Ú©Ø§Ù† Ù…ÛŒâ€ŒØ¨Ø§Ø´Ø¯ Ùˆ Ø¨Ø®Ø´ÛŒ Ø§Ø² Ø¢Ø±Ø´ÛŒÙˆ ØªØµØ§ÙˆÛŒØ± Ø§ÛŒÙ† Ø§Ù†Ø¬Ù…Ù† Ø§Ø³Øª.

Ø§ÛŒÙ† ØªØµÙˆÛŒØ± Ø¯Ø± ØªØ§Ø±ÛŒØ® {event_info.get('date', 'Ù†Ø§Ù…Ø´Ø®Øµ')} Ø«Ø¨Øª Ø´Ø¯Ù‡ Ø§Ø³Øª Ùˆ Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ ÙØ¹Ø§Ù„ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ø¹Ù„Ù…ÛŒ Ùˆ Ø¢Ù…ÙˆØ²Ø´ÛŒ Ø§Ù†Ø¬Ù…Ù† Ø¯Ø± Ø²Ù…ÛŒÙ†Ù‡ Ø±ÛŒÙ‡ Ú©ÙˆØ¯Ú©Ø§Ù† Ø§Ø³Øª."""
        
    elif "img_2025" in filename or "img-2025" in filename:
        # ØªØµØ§ÙˆÛŒØ± Ø®Ø¨Ø±
        category = "Ø®Ø¨Ø±"
        tags = "Ø®Ø¨Ø±,ØªØµÙˆÛŒØ±"
        
        date_match = re.search(r'(\d{4})(\d{2})(\d{2})', filename)
        if date_match:
            year, month, day = date_match.groups()
            title = f"ØªØµÙˆÛŒØ± Ø®Ø¨Ø± - {year}/{month}/{day}"
            event_info["date"] = f"{year}/{month}/{day}"
        else:
            title = "ØªØµÙˆÛŒØ± Ø®Ø¨Ø±"
        
        content = f"""Ø§ÛŒÙ† ØªØµÙˆÛŒØ± Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ø§Ø®Ø¨Ø§Ø± Ùˆ Ø±ÙˆÛŒØ¯Ø§Ø¯Ù‡Ø§ÛŒ Ø§Ù†Ø¬Ù…Ù† Ø¹Ù„Ù…ÛŒ Ø±ÛŒÙ‡ Ú©ÙˆØ¯Ú©Ø§Ù† Ø§ÛŒØ±Ø§Ù† Ø§Ø³Øª.

ØªØµÙˆÛŒØ± Ø¨Ø®Ø´ÛŒ Ø§Ø² Ø¢Ø±Ø´ÛŒÙˆ ØªØµØ§ÙˆÛŒØ± Ø®Ø¨Ø±ÛŒ Ø§ÛŒÙ† Ø§Ù†Ø¬Ù…Ù† Ù…ÛŒâ€ŒØ¨Ø§Ø´Ø¯ Ùˆ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ ÙØ¹Ø§Ù„ÛŒØªâ€ŒÙ‡Ø§ Ùˆ Ø±ÙˆÛŒØ¯Ø§Ø¯Ù‡Ø§ÛŒ Ø¹Ù„Ù…ÛŒ Ùˆ ØªØ®ØµØµÛŒ Ø¯Ø± Ø²Ù…ÛŒÙ†Ù‡ Ø¨ÛŒÙ…Ø§Ø±ÛŒâ€ŒÙ‡Ø§ÛŒ Ø±ÛŒÙˆÛŒ Ú©ÙˆØ¯Ú©Ø§Ù† Ø§Ø³Øª."""
        
    elif "image" in filename.lower():
        # ØªØµØ§ÙˆÛŒØ± Ø¹Ù…ÙˆÙ…ÛŒ
        category = "Ø¹Ù…ÙˆÙ…ÛŒ"
        tags = "ØªØµÙˆÛŒØ±,Ú¯Ø§Ù„Ø±ÛŒ"
        title = "ØªØµÙˆÛŒØ± Ú¯Ø§Ù„Ø±ÛŒ Ø§Ù†Ø¬Ù…Ù†"
        
        content = f"""Ø§ÛŒÙ† ØªØµÙˆÛŒØ± Ø§Ø² Ú¯Ø§Ù„Ø±ÛŒ ØªØµØ§ÙˆÛŒØ± Ø§Ù†Ø¬Ù…Ù† Ø¹Ù„Ù…ÛŒ Ø±ÛŒÙ‡ Ú©ÙˆØ¯Ú©Ø§Ù† Ø§ÛŒØ±Ø§Ù† Ø§Ø³Øª.

ØªØµÙˆÛŒØ± Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ ÙØ¹Ø§Ù„ÛŒØªâ€ŒÙ‡Ø§ Ùˆ Ø±ÙˆÛŒØ¯Ø§Ø¯Ù‡Ø§ÛŒ Ø§ÛŒÙ† Ø§Ù†Ø¬Ù…Ù† Ù…ÛŒâ€ŒØ¨Ø§Ø´Ø¯ Ùˆ Ø¨Ø®Ø´ÛŒ Ø§Ø² Ø¢Ø±Ø´ÛŒÙˆ ØªØµØ§ÙˆÛŒØ± Ø§Ø³Øª."""
        
    else:
        # Ø³Ø§ÛŒØ± ØªØµØ§ÙˆÛŒØ±
        title = file_stem.replace('_', ' ').replace('-', ' ')
        title = re.sub(r'\d{4}[-_]?\d{2}[-_]?\d{2}', '', title)
        title = re.sub(r'\(\d+\)', '', title)
        title = title.strip()
        
        if not title or len(title) < 3:
            title = f"ØªØµÙˆÛŒØ± {file_stem}"
        
        content = f"""Ø§ÛŒÙ† ØªØµÙˆÛŒØ± Ø¨Ø§ Ù†Ø§Ù… '{filename}' Ø¯Ø± Ú¯Ø§Ù„Ø±ÛŒ ØªØµØ§ÙˆÛŒØ± Ø§Ù†Ø¬Ù…Ù† Ø¹Ù„Ù…ÛŒ Ø±ÛŒÙ‡ Ú©ÙˆØ¯Ú©Ø§Ù† Ø§ÛŒØ±Ø§Ù† Ù‚Ø±Ø§Ø± Ø¯Ø§Ø±Ø¯.

ØªØµÙˆÛŒØ± Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ ÙØ¹Ø§Ù„ÛŒØªâ€ŒÙ‡Ø§ Ùˆ Ø±ÙˆÛŒØ¯Ø§Ø¯Ù‡Ø§ÛŒ Ø¹Ù„Ù…ÛŒ Ø§ÛŒÙ† Ø§Ù†Ø¬Ù…Ù† Ù…ÛŒâ€ŒØ¨Ø§Ø´Ø¯."""
    
    # Ø§Ú¯Ø± ØªØµÙˆÛŒØ± Ø®Ø§ØµÛŒ Ø±Ø§ Ù…ÛŒâ€ŒØ´Ù†Ø§Ø³ÛŒÙ…ØŒ Ù…Ø­ØªÙˆØ§ÛŒ Ø¯Ù‚ÛŒÙ‚â€ŒØªØ± Ø§Ø¶Ø§ÙÙ‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
    if "photo_2025-12-05_21-18-04" in filename:
        # Ø§ÛŒÙ† ØªØµÙˆÛŒØ± Ù¾Ø³Øª Ø§ÛŒÙ†Ø³ØªØ§Ú¯Ø±Ø§Ù… Ø³Ù…ÛŒÙ†Ø§Ø± Ø±Ø´Øª Ø§Ø³Øª
        content = """Ø§ÛŒÙ† ØªØµÙˆÛŒØ± ÛŒÚ© Ù¾Ø³Øª Ø§ÛŒÙ†Ø³ØªØ§Ú¯Ø±Ø§Ù… Ø§Ø² Ø³Ù…ÛŒÙ†Ø§Ø± Ø³Ø§Ù„Ø§Ù†Ù‡ Ø¨ÛŒÙ…Ø§Ø±ÛŒâ€ŒÙ‡Ø§ÛŒ Ø±ÛŒÙˆÛŒ Ú©ÙˆØ¯Ú©Ø§Ù† Ø§Ø³Øª Ú©Ù‡ Ø¯Ø± Ø´Ù‡Ø± Ø±Ø´Øª Ø¨Ø±Ú¯Ø²Ø§Ø± Ø´Ø¯Ù‡ Ø§Ø³Øª.

**Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø±ÙˆÛŒØ¯Ø§Ø¯:**
- Ø¹Ù†ÙˆØ§Ù†: Ø³Ù…ÛŒÙ†Ø§Ø± Ø³Ø§Ù„Ø§Ù†Ù‡ Ø¨ÛŒÙ…Ø§Ø±ÛŒâ€ŒÙ‡Ø§ÛŒ Ø±ÛŒÙˆÛŒ Ú©ÙˆØ¯Ú©Ø§Ù†
- Ù…Ú©Ø§Ù†: Ø±Ø´ØªØŒ Ù…Ø¬ØªÙ…Ø¹ Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ÛŒ Ø¹Ù„ÙˆÙ… Ù¾Ø²Ø´Ú©ÛŒ Ú¯ÛŒÙ„Ø§Ù†ØŒ Ø¯Ø§Ù†Ø´Ú©Ø¯Ù‡ Ø¯Ø§Ø±ÙˆØ³Ø§Ø²ÛŒ
- ØªØ§Ø±ÛŒØ®: Û² Ùˆ Û³ Ø¢Ø°Ø±Ù…Ø§Ù‡
- Ø¨Ø±Ú¯Ø²Ø§Ø±Ú©Ù†Ù†Ø¯Ù‡: Ø§Ù†Ø¬Ù…Ù† Ø¹Ù„Ù…ÛŒ Ø±ÛŒÙ‡ Ú©ÙˆØ¯Ú©Ø§Ù† Ø§ÛŒØ±Ø§Ù†
- Ù‡Ù…Ú©Ø§Ø±ÛŒ: Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ Ø¹Ù„ÙˆÙ… Ù¾Ø²Ø´Ú©ÛŒ Ú¯ÛŒÙ„Ø§Ù†
- Ú©Ø¯ Ø¨Ø±Ù†Ø§Ù…Ù‡: Û·Û°Û°Û¸Û²
- Ø´Ù…Ø§Ø±Ù‡ ØªÙ…Ø§Ø³: Û°Û¹Û°Û´Û¶Û¸ÛµÛ³Û¹Û²Û± Ùˆ Û°Û¹Û°Û±Û³Û¶Û¸Û´Û¸ÛµÛ¶

Ø§ÛŒÙ† Ø³Ù…ÛŒÙ†Ø§Ø± Ø¯Ø§Ø±Ø§ÛŒ Ø§Ù…ØªÛŒØ§Ø² Ø¨Ø§Ø²Ø¢Ù…ÙˆØ²ÛŒ Ø¨ÙˆØ¯Ù‡ Ùˆ Ø«Ø¨Øªâ€ŒÙ†Ø§Ù… Ø§Ø² Ø·Ø±ÛŒÙ‚ Ø³Ø§Ù…Ø§Ù†Ù‡ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ø§ÙˆÙ… Ø§Ù†Ø¬Ø§Ù… Ù…ÛŒâ€ŒØ´Ø¯Ù‡ Ø§Ø³Øª."""
        
        category = "Ù‡Ù…Ø§ÛŒØ´"
        tags = "Ù‡Ù…Ø§ÛŒØ´,Ø³Ù…ÛŒÙ†Ø§Ø±,Ø±Ø´Øª,Ú¯ÛŒÙ„Ø§Ù†,ØªØµÙˆÛŒØ±"
        title = "Ø³Ù…ÛŒÙ†Ø§Ø± Ø³Ø§Ù„Ø§Ù†Ù‡ Ø¨ÛŒÙ…Ø§Ø±ÛŒâ€ŒÙ‡Ø§ÛŒ Ø±ÛŒÙˆÛŒ Ú©ÙˆØ¯Ú©Ø§Ù† - Ø±Ø´Øª"
    
    slug = persian_to_slug(title)
    
    return {
        "type": "news",
        "title": title,
        "slug": slug,
        "content": content,
        "short_content": extract_short_content(content),
        "category": category,
        "tags": tags,
        "source": "Ø§Ù†Ø¬Ù…Ù† Ø¹Ù„Ù…ÛŒ Ø±ÛŒÙ‡ Ú©ÙˆØ¯Ú©Ø§Ù† Ø§ÛŒØ±Ø§Ù†",
        "image": f"Content/{filename}",
        "is_published": True,
        "author": 1,
        "views": 0,
        "file_path": None,
        "image_info": {
            "filename": filename,
            "file_size_kb": round(image_path.stat().st_size / 1024, 2),
            "extracted_at": datetime.now().isoformat()
        },
        "event_details": event_info if event_info else None
    }

def main():
    """ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ"""
    print("Ø´Ø±ÙˆØ¹ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø­ØªÙˆØ§ÛŒ Ù‡Ù…Ù‡ ØªØµØ§ÙˆÛŒØ±...")
    print("=" * 60)
    
    result = {
        "images_content": [],
        "metadata": {
            "extracted_at": datetime.now().isoformat(),
            "total_images": 0,
            "version": "1.0"
        }
    }
    
    # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ù‡Ù…Ù‡ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ ØªØµÙˆÛŒØ±ÛŒ
    image_extensions = ['.jpg', '.jpeg', '.png', '.gif', '.webp']
    image_files = []
    
    for ext in image_extensions:
        image_files.extend(list(CONTENT_DIR.glob(f"*{ext}")))
        image_files.extend(list(CONTENT_DIR.glob(f"*{ext.upper()}")))
    
    print(f"ğŸ“ ØªØ¹Ø¯Ø§Ø¯ ØªØµØ§ÙˆÛŒØ± Ù¾ÛŒØ¯Ø§ Ø´Ø¯Ù‡: {len(image_files)}")
    print()
    
    # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù‡Ø± ØªØµÙˆÛŒØ±
    for i, image_path in enumerate(image_files, 1):
        print(f"ğŸ–¼ï¸  [{i}/{len(image_files)}] Ù¾Ø±Ø¯Ø§Ø²Ø´: {image_path.name}")
        
        try:
            content = analyze_image_content(image_path)
            result["images_content"].append(content)
            print(f"   âœ“ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯: {content['title'][:50]}...")
        except Exception as e:
            print(f"   âœ— Ø®Ø·Ø§: {e}")
    
    # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø¢Ù…Ø§Ø±
    result["metadata"]["total_images"] = len(result["images_content"])
    
    # Ø°Ø®ÛŒØ±Ù‡ ÙØ§ÛŒÙ„ JSON
    print(f"\nğŸ’¾ Ø¯Ø± Ø­Ø§Ù„ Ø°Ø®ÛŒØ±Ù‡ ÙØ§ÛŒÙ„ JSON...")
    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    
    print("=" * 60)
    print(f"âœ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯!")
    print(f"\nğŸ“Š Ø¢Ù…Ø§Ø± Ù†Ù‡Ø§ÛŒÛŒ:")
    print(f"   ğŸ–¼ï¸  ØªØµØ§ÙˆÛŒØ± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡: {result['metadata']['total_images']}")
    print(f"\nğŸ“ ÙØ§ÛŒÙ„ Ø®Ø±ÙˆØ¬ÛŒ: {OUTPUT_FILE}")
    print("=" * 60)

if __name__ == "__main__":
    main()

